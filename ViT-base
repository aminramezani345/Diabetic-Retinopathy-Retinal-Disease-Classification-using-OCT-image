pip install transformers datasets pillow torch torchvision
pip install datasets
from transformers import ViTForImageClassification, ViTImageProcessor, Trainer, TrainingArguments, DefaultDataCollator
from datasets import Dataset, load_metric
from PIL import Image
import os
train_path = '/Users/chaitanyakakade/Downloads/colored_images'
val_path = '/Users/chaitanyakakade/Downloads/colored_images_split' 


def load_images_and_labels(folder_path):
    image_files = []
    labels = []
    label_map = {folder: idx for idx, folder in enumerate(os.listdir(folder_path)) if os.path.isdir(os.path.join(folder_path, folder))}
    for label, label_idx in label_map.items():
        label_path = os.path.join(folder_path, label)
        for file_name in os.listdir(label_path):
            if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_files.append(os.path.join(label_path, file_name))
                labels.append(label_idx)
    return image_files, labels


train_images, train_labels = load_images_and_labels(train_path)
val_images, val_labels = load_images_and_labels(val_path)
train_dataset = Dataset.from_dict({"file_paths": train_images, "labels": train_labels})
val_dataset = Dataset.from_dict({"file_paths": val_images, "labels": val_labels})


processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=len(set(train_labels)))


def preprocess_function(examples):
    images = [Image.open(img).convert("RGB") for img in examples['file_paths']]
    return processor(images=images, return_tensors="pt")


train_dataset = train_dataset.map(preprocess_function, batched=True)
val_dataset = val_dataset.map(preprocess_function, batched=True)


data_collator = DefaultDataCollator()

training_args = TrainingArguments(
    output_dir='./results',  
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=10,
    weight_decay=0.01,
    logging_dir='./logs',
)


trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=data_collator,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=processor  
)


trainer.train()


results = trainer.evaluate()

print(f"Accuracy: {results['eval_accuracy']:.4f}")



